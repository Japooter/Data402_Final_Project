{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b84cf89-01fa-4050-85a5-f4c2108dbe33",
   "metadata": {},
   "source": [
    "# Ingestion and Cleaning of the academy csv files\n",
    "In the academy bucket, there is data stored in csv files. This data describes each candidates assessed scores across their time in the academy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4632da25-07b6-4312-9057-42e7220b5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, csv, boto3, datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8efc9aa7-3ec7-44ad-a018-c27cfb08d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0965058-cd15-490c-93fd-48aa3ec51a95",
   "metadata": {},
   "source": [
    "### We create a function to list all object within a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66c0a1c3-c8f2-45ab-92fd-616121131a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(bucket, prefix):\n",
    "    response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        return [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99d584cd-24a1-4ef6-a77f-2aea3639e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_objects(bucket, prefix):\n",
    "    all_objects = []\n",
    "    continuation_token = None\n",
    "    \n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=continuation_token)\n",
    "        else:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            all_objects.extend([obj['Key'] for obj in response['Contents']])\n",
    "        \n",
    "        if not response.get('NextContinuationToken'):\n",
    "            break\n",
    "        \n",
    "        continuation_token = response['NextContinuationToken']\n",
    "    \n",
    "    return all_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e81eee-2e0f-4158-81ad-e2112da0fdcd",
   "metadata": {},
   "source": [
    "## We load in the academy data.\n",
    "Since we know that the academy bucket only contains these csv files, we don't need to perform any checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "047b5c6f-cb6c-4b7c-a46f-3e49e0d2178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_academy_data(bucket, prefix):\n",
    "    files = list_all_objects(bucket, prefix)\n",
    "    data_frames = []\n",
    "    for file_key in files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        df = pd.read_csv(obj['Body'])\n",
    "        file_name = file_key.split(\"/\")[1].split(\".\")[0]\n",
    "        df.insert(0,'filename', file_name, True)\n",
    "        data_frames.append(df)\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3438b9b2-a5b2-45d2-a372-c97fd525d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data = load_academy_data('data-402-final-project', 'Academy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "240f1a30-46e1-4df7-83d4-4d61b8e1fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_whitespace(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3c65fda-2d17-4a4e-91d6-6f5717a11a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category', 'Stream', 'Date', 'name', 'trainer', 'Analytic_W1', 'Independent_W1', 'Determined_W1', 'Professional_W1', 'Studious_W1', 'Imaginative_W1', 'Analytic_W2', 'Independent_W2', 'Determined_W2', 'Professional_W2', 'Studious_W2', 'Imaginative_W2', 'Analytic_W3', 'Independent_W3', 'Determined_W3', 'Professional_W3', 'Studious_W3', 'Imaginative_W3', 'Analytic_W4', 'Independent_W4', 'Determined_W4', 'Professional_W4', 'Studious_W4', 'Imaginative_W4', 'Analytic_W5', 'Independent_W5', 'Determined_W5', 'Professional_W5', 'Studious_W5', 'Imaginative_W5', 'Analytic_W6', 'Independent_W6', 'Determined_W6', 'Professional_W6', 'Studious_W6', 'Imaginative_W6', 'Analytic_W7', 'Independent_W7', 'Determined_W7', 'Professional_W7', 'Studious_W7', 'Imaginative_W7', 'Analytic_W8', 'Independent_W8', 'Determined_W8', 'Professional_W8', 'Studious_W8', 'Imaginative_W8', 'Analytic_W9', 'Independent_W9', 'Determined_W9', 'Professional_W9', 'Studious_W9', 'Imaginative_W9', 'Analytic_W10', 'Independent_W10', 'Determined_W10', 'Professional_W10', 'Studious_W10', 'Imaginative_W10']\n"
     ]
    }
   ],
   "source": [
    "cols = list(academy_data.columns.values)\n",
    "for col in cols:\n",
    "    academy_data[col] = academy_data[col].appl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab7cef-9d8e-4635-bd57-bd373b13048f",
   "metadata": {},
   "source": [
    "### Next we need to extract the caterogry, stream name, and start date from the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "422c7a8c-2790-4952-a047-ca19d1cc5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(filename):\n",
    "    splits = filename.split(\"_\")\n",
    "    category = splits[0]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4271d1e-4100-4272-aaa2-0130f1909624",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data['Category'] = academy_data['filename'].apply(get_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26fdcec7-6d41-451b-97bd-821bc65e7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream(filename):\n",
    "    splits = filename.split(\"_\")\n",
    "    stream_name = \"\".join(splits[0:2])\n",
    "    return stream_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2e23bfe-a4af-4ca9-81f6-fdd8c497f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data['Stream'] = academy_data['filename'].apply(get_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e7d2c93-e349-4a88-8291-8c69539dd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(filename):\n",
    "    splits = filename.split(\"_\")\n",
    "    date = datetime.datetime.strptime(splits[2], \"%Y-%m-%d\").date()\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e1a27bf-fe95-49bc-be1a-3691c6a750ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data['Date'] = academy_data['filename'].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9157ea52-bca8-4036-ae84-c6c790e14811",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data = academy_data[['Category', 'Stream', 'Date'] + [col for col in academy_data if col not in ['Category','Stream', 'Date','filename']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3265fad-271f-4ecf-9c6d-c0ca5ef90d4c",
   "metadata": {},
   "source": [
    "#### Next we check for any duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5812856a-3e1b-4daf-8d32-b4903dae4cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c54c9-4d2a-4fd0-8a33-251bfdc9c3c2",
   "metadata": {},
   "source": [
    "There are no duplicate values in our table\n",
    "### Finally, we look to see if where there are null values\n",
    "We don't want any null values in Category, Stram, Date, name, and trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d10b991-4695-45fa-8909-6251ba283e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category              0\n",
       "Stream                0\n",
       "Date                  0\n",
       "name                  0\n",
       "trainer               0\n",
       "                   ... \n",
       "Independent_W10     235\n",
       "Determined_W10      235\n",
       "Professional_W10    235\n",
       "Studious_W10        235\n",
       "Imaginative_W10     235\n",
       "Length: 65, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "academy_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9906385-1f73-440a-97e4-0f0daf69a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data['Category'] = academy_data['Category'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241aaefa-9e5b-422e-b415-a29bba12f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(academy_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
