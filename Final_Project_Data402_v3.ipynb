{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c4c49b2-df09-41f0-bd0f-13fa9fb526ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.34.117)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.117 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3) (1.34.117)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from botocore<1.35.0,>=1.34.117->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from botocore<1.35.0,>=1.34.117->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raj_a\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.117->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5066c6fb-a712-4226-9884-463e89b164ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d917eea-8c97-476b-859f-df39676e58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abadfa7c-e698-400a-9bbb-9ef7ec6c0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(bucket, prefix):\n",
    "    response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        return [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e8a262a-db93-4bab-8d2b-f9839523c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_objects(bucket, prefix):\n",
    "    all_objects = []\n",
    "    continuation_token = None\n",
    "    \n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=continuation_token)\n",
    "        else:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            all_objects.extend([obj['Key'] for obj in response['Contents']])\n",
    "        \n",
    "        if not response.get('NextContinuationToken'):\n",
    "            break\n",
    "        \n",
    "        continuation_token = response['NextContinuationToken']\n",
    "    \n",
    "    return all_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "01aa6dc8-ac33-47bd-be98-4fd1b7035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_types(bucket, prefix):\n",
    "    files = list_all_objects(bucket, prefix)\n",
    "    file_types = {}\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "        if ext in file_types:\n",
    "            file_types[ext] += 1\n",
    "        else:\n",
    "            file_types[ext] = 1\n",
    "    return file_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a00480ca-aeaa-40cf-a336-366304741770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_file_types(bucket, prefix, name):\n",
    "    file_types = get_file_types(bucket, prefix)\n",
    "    print(f\"{name}\")\n",
    "    for ext, count in file_types.items():\n",
    "        print(f\"{ext.upper()} files: {count}\")\n",
    "    other_files = sum([count for ext, count in file_types.items() if ext not in ['.csv', '.json', '.txt']])\n",
    "    print(f\"Other file types: {other_files}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ffdba537-93d7-445f-a187-a49654e8f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_academy_data(bucket, prefix):\n",
    "    files = list_all_objects(bucket, prefix)\n",
    "    data_frames = []\n",
    "    for file_key in files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        df = pd.read_csv(obj['Body'])\n",
    "        data_frames.append(df)\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4f2d292-bc2d-487c-b44f-cc0861a887dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_talent_data(bucket, prefix):\n",
    "    files = list_all_objects(bucket, prefix)\n",
    "    records = []\n",
    "    for file_key in files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        content = obj['Body'].read().decode('utf-8')\n",
    "        try:\n",
    "            # Attempt to load the content as JSON\n",
    "            data = json.loads(content)\n",
    "            records.append(data)\n",
    "        except json.JSONDecodeError:\n",
    "            # If content is not JSON, try to parse as CSV\n",
    "            try:\n",
    "                csv_reader = csv.DictReader(content.splitlines())\n",
    "                # Convert CSV rows to dicts & append to records list\n",
    "                for row in csv_reader:\n",
    "                    records.append(row)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {file_key}: {e}\")\n",
    "                # Handle the error appropriately,-> skip the file or handle it differently\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82aecf2e-b67e-425c-902e-c687ef8992e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_columns(bucket, prefix, name):\n",
    "    files = list_all_objects(bucket, prefix)\n",
    "    columns = {}\n",
    "    for file_key in files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        ext = os.path.splitext(file_key)[1].lower()\n",
    "        if ext == '.csv':\n",
    "            df = pd.read_csv(obj['Body'])\n",
    "            columns[ext] = list(df.columns)\n",
    "        elif ext == '.json':\n",
    "            content = obj['Body'].read().decode('utf-8')\n",
    "            data = json.loads(content)\n",
    "            if isinstance(data, list):\n",
    "                columns[ext] = list(data[0].keys())\n",
    "            elif isinstance(data, dict):\n",
    "                columns[ext] = list(data.keys())\n",
    "        elif ext == '.txt':\n",
    "            content = obj['Body'].read().decode('utf-8')\n",
    "            first_line = content.splitlines()[0]\n",
    "            columns[ext] = first_line.split()\n",
    "        else:\n",
    "            columns[ext] = ['no columns']\n",
    "    \n",
    "    print(f\"{name}\")\n",
    "    for ext, cols in columns.items():\n",
    "        print(f\"{ext.upper()} files columns: {', '.join(cols) if cols else 'no columns'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "012fae85-0c25-41a9-a1ef-a37b87d30658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_merged_columns(merged_data, academy_columns, talent_columns):\n",
    "    all_columns = set(academy_columns).union(set(talent_columns))\n",
    "    missing_columns = all_columns.difference(set(merged_data.columns))\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(\"The following columns are missing from the merged data:\")\n",
    "        print(\", \".join(missing_columns))\n",
    "    else:\n",
    "        print(\"All columns are present in the merged data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "35fbd60d-d562-4712-9c4b-f7522af9012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy\n",
      ".CSV files: 36\n",
      "Other file types: 0\n",
      "\n",
      "Talent\n",
      ".JSON files: 3105\n",
      ".CSV files: 12\n",
      ".TXT files: 152\n",
      "Other file types: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_file_types('data-402-final-project', 'Academy/', 'Academy')\n",
    "print_file_types('data-402-final-project', 'Talent/', 'Talent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e1319479-2009-42b9-8470-a4357dbc008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy\n",
      ".CSV files columns: name, trainer, Analytic_W1, Independent_W1, Determined_W1, Professional_W1, Studious_W1, Imaginative_W1, Analytic_W2, Independent_W2, Determined_W2, Professional_W2, Studious_W2, Imaginative_W2, Analytic_W3, Independent_W3, Determined_W3, Professional_W3, Studious_W3, Imaginative_W3, Analytic_W4, Independent_W4, Determined_W4, Professional_W4, Studious_W4, Imaginative_W4, Analytic_W5, Independent_W5, Determined_W5, Professional_W5, Studious_W5, Imaginative_W5, Analytic_W6, Independent_W6, Determined_W6, Professional_W6, Studious_W6, Imaginative_W6, Analytic_W7, Independent_W7, Determined_W7, Professional_W7, Studious_W7, Imaginative_W7, Analytic_W8, Independent_W8, Determined_W8, Professional_W8, Studious_W8, Imaginative_W8\n",
      "\n",
      "Talent\n",
      ".JSON files columns: name, date, tech_self_score, strengths, weaknesses, self_development, geo_flex, financial_support_self, result, course_interest\n",
      ".CSV files columns: id, name, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by\n",
      ".TXT files columns: Wednesday, 9, October, 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_columns('data-402-final-project', 'Academy/', 'Academy')\n",
    "list_columns('data-402-final-project', 'Talent/', 'Talent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd51f717-baa1-4cb2-8a1c-cc80f280eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data = load_academy_data('data-402-final-project', 'Academy/')\n",
    "talent_data = load_talent_data('data-402-final-project', 'Talent/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf310af2-e2f6-480e-b68f-500798f895f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique names from academy_data and talent_data\n",
    "academy_names = set(academy_data['name'])\n",
    "talent_names = set(talent_data['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4b2b475-3fed-4d3a-96a9-de1780220cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each name in academy_data exists in talent_data\n",
    "common_names = [name for name in academy_names if name in talent_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d6bf483-dc06-448c-85ab-dbb80789975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names from academy_data found in talent_data: 397\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of names from academy_data found in talent_data:\", len(common_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "239e78d9-6842-4f3a-b819-af5ded046960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Academy Data:\n",
      "Number of rows: 397\n",
      "Number of columns: 62\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of Academy Data:\")\n",
    "print(f\"Number of rows: {academy_data.shape[0]}\")\n",
    "print(f\"Number of columns: {academy_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b88b2eaf-7e4c-42ba-84eb-939ec5d628b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of Talent Data:\n",
      "Number of rows: 12082\n",
      "Number of columns: 176\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensions of Talent Data:\")\n",
    "print(f\"Number of rows: {talent_data.shape[0]}\")\n",
    "print(f\"Number of columns: {talent_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e9b39f38-f839-4a61-a287-e6b1d0ec2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy Data:\n",
      "              name       trainer  Analytic_W1  Independent_W1  Determined_W1  \\\n",
      "0  Quintus Penella  Gregor Gomez            1               2              2   \n",
      "1     Simon Murrey  Gregor Gomez            6               1              1   \n",
      "2      Gustaf Lude  Gregor Gomez            6               4              1   \n",
      "3    Yolanda Fosse  Gregor Gomez            2               1              2   \n",
      "4     Lynnett Swin  Gregor Gomez            2               2              4   \n",
      "\n",
      "   Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2  Independent_W2  \\\n",
      "0                1            2               2          NaN             NaN   \n",
      "1                2            4               2          3.0             1.0   \n",
      "2                1            2               3          1.0             1.0   \n",
      "3                3            3               3          4.0             2.0   \n",
      "4                5            1               2          3.0             2.0   \n",
      "\n",
      "   ...  Determined_W9  Professional_W9  Studious_W9  Imaginative_W9  \\\n",
      "0  ...            NaN              NaN          NaN             NaN   \n",
      "1  ...            NaN              NaN          NaN             NaN   \n",
      "2  ...            NaN              NaN          NaN             NaN   \n",
      "3  ...            NaN              NaN          NaN             NaN   \n",
      "4  ...            NaN              NaN          NaN             NaN   \n",
      "\n",
      "   Analytic_W10  Independent_W10  Determined_W10  Professional_W10  \\\n",
      "0           NaN              NaN             NaN               NaN   \n",
      "1           NaN              NaN             NaN               NaN   \n",
      "2           NaN              NaN             NaN               NaN   \n",
      "3           NaN              NaN             NaN               NaN   \n",
      "4           NaN              NaN             NaN               NaN   \n",
      "\n",
      "   Studious_W10  Imaginative_W10  \n",
      "0           NaN              NaN  \n",
      "1           NaN              NaN  \n",
      "2           NaN              NaN  \n",
      "3           NaN              NaN  \n",
      "4           NaN              NaN  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Academy Data:\")\n",
    "print(academy_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c37bb9a-c05e-4a4a-a77f-2395cf1a2c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Talent Data:\n",
      "                name        date  \\\n",
      "0  Stillmann Castano  22/08/2019   \n",
      "1    Hilary Willmore  01/08/2019   \n",
      "2      Efrem Whipple  22/08/2019   \n",
      "3        Sydel Fenne  28/08/2019   \n",
      "4    Michel Lebarree  07/08/2019   \n",
      "\n",
      "                                     tech_self_score  \\\n",
      "0      {'C#': 6, 'Java': 5, 'R': 2, 'JavaScript': 2}   \n",
      "1        {'Python': 1, 'C#': 4, 'Java': 2, 'C++': 4}   \n",
      "2                              {'Ruby': 4, 'C++': 4}   \n",
      "3                             {'Java': 3, 'SPSS': 4}   \n",
      "4  {'Python': 3, 'Java': 4, 'Ruby': 1, 'R': 2, 'P...   \n",
      "\n",
      "                             strengths                            weaknesses  \\\n",
      "0                           [Charisma]  [Distracted, Impulsive, Introverted]   \n",
      "1  [Patient, Curious, Problem Solving]    [Overbearing, Chatty, Indifferent]   \n",
      "2    [Courteous, Independent, Patient]     [Introverted, Impulsive, Anxious]   \n",
      "3                         [Passionate]            [Perfectionist, Sensitive]   \n",
      "4                          [Versatile]  [Controlling, Perfectionist, Chatty]   \n",
      "\n",
      "  self_development geo_flex financial_support_self result course_interest  \\\n",
      "0              Yes      Yes                    Yes   Pass        Business   \n",
      "1               No      Yes                    Yes   Fail            Data   \n",
      "2              Yes      Yes                    Yes   Pass        Business   \n",
      "3              Yes      Yes                    Yes   Pass            Data   \n",
      "4              Yes      Yes                    Yes   Pass     Engineering   \n",
      "\n",
      "   ... Thursday 7 November 2019 Thursday 8 August 2019 Tuesday 8 January 2019  \\\n",
      "0  ...                      NaN                    NaN                    NaN   \n",
      "1  ...                      NaN                    NaN                    NaN   \n",
      "2  ...                      NaN                    NaN                    NaN   \n",
      "3  ...                      NaN                    NaN                    NaN   \n",
      "4  ...                      NaN                    NaN                    NaN   \n",
      "\n",
      "  Wednesday 8 May 2019 Tuesday 8 October 2019 Tuesday 9 April 2019  \\\n",
      "0                  NaN                    NaN                  NaN   \n",
      "1                  NaN                    NaN                  NaN   \n",
      "2                  NaN                    NaN                  NaN   \n",
      "3                  NaN                    NaN                  NaN   \n",
      "4                  NaN                    NaN                  NaN   \n",
      "\n",
      "  Wednesday 9 January 2019 Tuesday 9 July 2019 Thursday 9 May 2019  \\\n",
      "0                      NaN                 NaN                 NaN   \n",
      "1                      NaN                 NaN                 NaN   \n",
      "2                      NaN                 NaN                 NaN   \n",
      "3                      NaN                 NaN                 NaN   \n",
      "4                      NaN                 NaN                 NaN   \n",
      "\n",
      "  Wednesday 9 October 2019  \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "2                      NaN  \n",
      "3                      NaN  \n",
      "4                      NaN  \n",
      "\n",
      "[5 rows x 176 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTalent Data:\")\n",
    "print(talent_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bfee7811-81de-4f9a-9834-b21065fe7f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Academy Data:\n",
      "name                  0\n",
      "trainer               0\n",
      "Analytic_W1           0\n",
      "Independent_W1        0\n",
      "Determined_W1         0\n",
      "                   ... \n",
      "Independent_W10     235\n",
      "Determined_W10      235\n",
      "Professional_W10    235\n",
      "Studious_W10        235\n",
      "Imaginative_W10     235\n",
      "Length: 62, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Academy Data:\")\n",
    "print(academy_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b9cba71-7cfa-446b-8525-7c0efac95f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_data_filled = academy_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6b5f6418-eb4a-4744-aa3f-6f61d9fb3d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Academy Data:\n",
      "name                  0\n",
      "trainer               0\n",
      "Analytic_W1           0\n",
      "Independent_W1        0\n",
      "Determined_W1         0\n",
      "                   ... \n",
      "Independent_W10     235\n",
      "Determined_W10      235\n",
      "Professional_W10    235\n",
      "Studious_W10        235\n",
      "Imaginative_W10     235\n",
      "Length: 62, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Academy Data:\")\n",
    "print(academy_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4e19b0ce-c580-4252-9f9d-219cf4cc3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Talent Data:\n",
      "name                         4286\n",
      "date                         8977\n",
      "tech_self_score              9032\n",
      "strengths                    8977\n",
      "weaknesses                   8977\n",
      "                            ...  \n",
      "Tuesday 9 April 2019        12047\n",
      "Wednesday 9 January 2019    12060\n",
      "Tuesday 9 July 2019         12042\n",
      "Thursday 9 May 2019         12057\n",
      "Wednesday 9 October 2019    12061\n",
      "Length: 176, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Talent Data:\")\n",
    "print(talent_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "44ca1dd5-8e99-4d69-966d-0cb7f9087342",
   "metadata": {},
   "outputs": [],
   "source": [
    "talent_data_filled = talent_data.fillna({\n",
    "    'tech_self_score': '{}', \n",
    "    'strengths': '[]', \n",
    "    'weaknesses': '[]',\n",
    "    'self_development': 'No', \n",
    "    'geo_flex': 'No', \n",
    "    'financial_support_self': 'No', \n",
    "    'course_interest': 'None'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "435d5afb-aea3-4f0d-810f-467250f69acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Talent Data:\n",
      "name                         4286\n",
      "date                         8977\n",
      "tech_self_score              9032\n",
      "strengths                    8977\n",
      "weaknesses                   8977\n",
      "                            ...  \n",
      "Tuesday 9 April 2019        12047\n",
      "Wednesday 9 January 2019    12060\n",
      "Tuesday 9 July 2019         12042\n",
      "Thursday 9 May 2019         12057\n",
      "Wednesday 9 October 2019    12061\n",
      "Length: 176, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Talent Data:\")\n",
    "print(talent_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "efad872b-a9b5-40f8-8658-e6a0941d30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique names from academy_data and talent_data\n",
    "academy_names = set(academy_data_filled['name'])\n",
    "talent_names = set(talent_data_filled['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0754b9b9-8a8f-4e0a-a12b-6524f6c9d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each name in academy_data exists in talent_data\n",
    "common_names = [name for name in academy_names if name in talent_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "edade6f3-4652-41c2-b20a-271520965bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names from academy_data found in talent_data: 397\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of names from academy_data found in talent_data:\", len(common_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f6b370f-a85f-4af1-9971-40a4fc0c5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dicts and lists to strings in specified columns\n",
    "talent_data_filled['tech_self_score'] = talent_data_filled['tech_self_score'].apply(json.dumps)\n",
    "talent_data_filled['strengths'] = talent_data_filled['strengths'].apply(json.dumps)\n",
    "talent_data_filled['weaknesses'] = talent_data_filled['weaknesses'].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "85c2ebfd-a98e-4c07-8367-5c99e8740cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ THIS IS A TESTTTR!!!!!!!!!!\n",
    "\n",
    "# Extract unique names from academy_data and talent_data\n",
    "academy_names = set(academy_data_filled['name'])\n",
    "talent_names = set(talent_data_filled['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "976a3faa-bebc-46f5-b6c1-a53301ecdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each name in academy_data exists in talent_data\n",
    "common_names = [name for name in academy_names if name in talent_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a9d40ef7-ec1b-4c5c-9618-b734ea3316a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names from academy_data found in talent_data: 397\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of names from academy_data found in talent_data:\", len(common_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "41cb6cb0-fde6-4b34-97b4-2e86c4dcb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after converting JSON strings back to lists/dictionaries:\n",
      "name                        object\n",
      "date                        object\n",
      "tech_self_score             object\n",
      "strengths                   object\n",
      "weaknesses                  object\n",
      "                             ...  \n",
      "Tuesday 9 April 2019        object\n",
      "Wednesday 9 January 2019    object\n",
      "Tuesday 9 July 2019         object\n",
      "Thursday 9 May 2019         object\n",
      "Wednesday 9 October 2019    object\n",
      "Length: 176, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "talent_data_filled['tech_self_score'] = talent_data_filled['tech_self_score'].apply(ast.literal_eval)\n",
    "talent_data_filled['strengths'] = talent_data_filled['strengths'].apply(ast.literal_eval)\n",
    "talent_data_filled['weaknesses'] = talent_data_filled['weaknesses'].apply(ast.literal_eval)\n",
    "\n",
    "print(\"Data types after converting JSON strings back to lists/dictionaries:\")\n",
    "print(talent_data_filled.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b6c239dc-b7f6-49b7-acde-fe73b105aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ THIS IS A TESTTTR!!!!!!!!!!\n",
    "\n",
    "# Extract unique names from academy_data and talent_data\n",
    "academy_names = set(academy_data_filled['name'])\n",
    "talent_names = set(talent_data_filled['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c7d0027-a304-4f0d-9875-c2e3b154e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each name in academy_data exists in talent_data\n",
    "common_names = [name for name in academy_names if name in talent_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "373a215f-46de-4b44-8f7a-cfe68806a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names from academy_data found in talent_data: 397\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of names from academy_data found in talent_data:\", len(common_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "69b40ea3-dc64-4dc2-b26a-3e10b40d11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge academy_data_filled and talent_data_filled on the 'name' column\n",
    "merged_data = pd.merge(academy_data_filled, talent_data_filled, on='name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "67daa6cd-8a5a-44bc-9ad0-f145ab456510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data:\n",
      "              name       trainer  Analytic_W1  Independent_W1  Determined_W1  \\\n",
      "0  Quintus Penella  Gregor Gomez            1               2              2   \n",
      "1  Quintus Penella  Gregor Gomez            1               2              2   \n",
      "2     Simon Murrey  Gregor Gomez            6               1              1   \n",
      "3     Simon Murrey  Gregor Gomez            6               1              1   \n",
      "4      Gustaf Lude  Gregor Gomez            6               4              1   \n",
      "\n",
      "   Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2  Independent_W2  \\\n",
      "0                1            2               2          0.0             0.0   \n",
      "1                1            2               2          0.0             0.0   \n",
      "2                2            4               2          3.0             1.0   \n",
      "3                2            4               2          3.0             1.0   \n",
      "4                1            2               3          1.0             1.0   \n",
      "\n",
      "   ...  Thursday 7 November 2019  Thursday 8 August 2019  \\\n",
      "0  ...                       NaN                     NaN   \n",
      "1  ...                       NaN                     NaN   \n",
      "2  ...                       NaN                     NaN   \n",
      "3  ...                       NaN                     NaN   \n",
      "4  ...                       NaN                     NaN   \n",
      "\n",
      "   Tuesday 8 January 2019  Wednesday 8 May 2019  Tuesday 8 October 2019  \\\n",
      "0                     NaN                   NaN                     NaN   \n",
      "1                     NaN                   NaN                     NaN   \n",
      "2                     NaN                   NaN                     NaN   \n",
      "3                     NaN                   NaN                     NaN   \n",
      "4                     NaN                   NaN                     NaN   \n",
      "\n",
      "   Tuesday 9 April 2019  Wednesday 9 January 2019  Tuesday 9 July 2019  \\\n",
      "0                   NaN                       NaN                  NaN   \n",
      "1                   NaN                       NaN                  NaN   \n",
      "2                   NaN                       NaN                  NaN   \n",
      "3                   NaN                       NaN                  NaN   \n",
      "4                   NaN                       NaN                  NaN   \n",
      "\n",
      "   Thursday 9 May 2019  Wednesday 9 October 2019  \n",
      "0                  NaN                       NaN  \n",
      "1                  NaN                       NaN  \n",
      "2                  NaN                       NaN  \n",
      "3                  NaN                       NaN  \n",
      "4                  NaN                       NaN  \n",
      "\n",
      "[5 rows x 237 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerged Data:\")\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c8d47eee-7311-45da-ba8e-66337c066578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names from both academy_data and talent_data\n",
    "academy_columns = list(academy_data.columns)\n",
    "talent_columns = list(talent_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c882f8e-f218-44b3-93dd-2b574670195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are present in the merged data.\n"
     ]
    }
   ],
   "source": [
    "# Check if all columns are present in the merged dataframe\n",
    "check_merged_columns(merged_data, academy_columns, talent_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e765c6c6-7b66-4038-98c7-6b9d9f9cff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered records for Simon Murrey:\n",
      "           name       trainer  Analytic_W1  Independent_W1  Determined_W1  \\\n",
      "2  Simon Murrey  Gregor Gomez            6               1              1   \n",
      "3  Simon Murrey  Gregor Gomez            6               1              1   \n",
      "\n",
      "   Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2  Independent_W2  \\\n",
      "2                2            4               2          3.0             1.0   \n",
      "3                2            4               2          3.0             1.0   \n",
      "\n",
      "   ...  Thursday 7 November 2019  Thursday 8 August 2019  \\\n",
      "2  ...                       NaN                     NaN   \n",
      "3  ...                       NaN                     NaN   \n",
      "\n",
      "   Tuesday 8 January 2019  Wednesday 8 May 2019  Tuesday 8 October 2019  \\\n",
      "2                     NaN                   NaN                     NaN   \n",
      "3                     NaN                   NaN                     NaN   \n",
      "\n",
      "   Tuesday 9 April 2019  Wednesday 9 January 2019  Tuesday 9 July 2019  \\\n",
      "2                   NaN                       NaN                  NaN   \n",
      "3                   NaN                       NaN                  NaN   \n",
      "\n",
      "   Thursday 9 May 2019  Wednesday 9 October 2019  \n",
      "2                  NaN                       NaN  \n",
      "3                  NaN                       NaN  \n",
      "\n",
      "[2 rows x 237 columns]\n",
      "\n",
      "All columns for Simon Murrey:\n",
      "           name       trainer  Analytic_W1  Independent_W1  Determined_W1  \\\n",
      "2  Simon Murrey  Gregor Gomez            6               1              1   \n",
      "3  Simon Murrey  Gregor Gomez            6               1              1   \n",
      "\n",
      "   Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2  Independent_W2  \\\n",
      "2                2            4               2          3.0             1.0   \n",
      "3                2            4               2          3.0             1.0   \n",
      "\n",
      "   ...  Thursday 7 November 2019  Thursday 8 August 2019  \\\n",
      "2  ...                       NaN                     NaN   \n",
      "3  ...                       NaN                     NaN   \n",
      "\n",
      "   Tuesday 8 January 2019  Wednesday 8 May 2019  Tuesday 8 October 2019  \\\n",
      "2                     NaN                   NaN                     NaN   \n",
      "3                     NaN                   NaN                     NaN   \n",
      "\n",
      "   Tuesday 9 April 2019  Wednesday 9 January 2019  Tuesday 9 July 2019  \\\n",
      "2                   NaN                       NaN                  NaN   \n",
      "3                   NaN                       NaN                  NaN   \n",
      "\n",
      "   Thursday 9 May 2019  Wednesday 9 October 2019  \n",
      "2                  NaN                       NaN  \n",
      "3                  NaN                       NaN  \n",
      "\n",
      "[2 rows x 237 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test search for a user\n",
    "simon_murrey_records = merged_data[merged_data['name'] == 'Simon Murrey']\n",
    "simon_murrey_records_all_columns = merged_data.loc[merged_data['name'] == 'Simon Murrey']\n",
    "# Filtered records for Simon Murrey\n",
    "print(\"Filtered records for Simon Murrey:\")\n",
    "print(simon_murrey_records)\n",
    "\n",
    "# All columns for Simon Murrey\n",
    "print(\"\\nAll columns for Simon Murrey:\")\n",
    "print(simon_murrey_records_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6329911-c552-4d96-838b-5542d96632d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered records for Gregor Gomez:\n",
      "Empty DataFrame\n",
      "Columns: [name, trainer, Analytic_W1, Independent_W1, Determined_W1, Professional_W1, Studious_W1, Imaginative_W1, Analytic_W2, Independent_W2, Determined_W2, Professional_W2, Studious_W2, Imaginative_W2, Analytic_W3, Independent_W3, Determined_W3, Professional_W3, Studious_W3, Imaginative_W3, Analytic_W4, Independent_W4, Determined_W4, Professional_W4, Studious_W4, Imaginative_W4, Analytic_W5, Independent_W5, Determined_W5, Professional_W5, Studious_W5, Imaginative_W5, Analytic_W6, Independent_W6, Determined_W6, Professional_W6, Studious_W6, Imaginative_W6, Analytic_W7, Independent_W7, Determined_W7, Professional_W7, Studious_W7, Imaginative_W7, Analytic_W8, Independent_W8, Determined_W8, Professional_W8, Studious_W8, Imaginative_W8, Analytic_W9, Independent_W9, Determined_W9, Professional_W9, Studious_W9, Imaginative_W9, Analytic_W10, Independent_W10, Determined_W10, Professional_W10, Studious_W10, Imaginative_W10, date, tech_self_score, strengths, weaknesses, self_development, geo_flex, financial_support_self, result, course_interest, id, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by, Thursday 1 August 2019, None, Wednesday 1 May 2019, Tuesday 1 October 2019, Wednesday 10 April 2019, Tuesday 10 December 2019, Thursday 10 January 2019, Wednesday 10 July 2019, Thursday 10 October 2019, Tuesday 10 September 2019, Thursday 11 April 2019, Wednesday 11 December 2019, Thursday 11 July 2019, Tuesday 11 June 2019, Wednesday 11 September 2019, Thursday 12 December 2019, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 237 columns]\n",
      "\n",
      "All columns for Gregor Gomez:\n",
      "Empty DataFrame\n",
      "Columns: [name, trainer, Analytic_W1, Independent_W1, Determined_W1, Professional_W1, Studious_W1, Imaginative_W1, Analytic_W2, Independent_W2, Determined_W2, Professional_W2, Studious_W2, Imaginative_W2, Analytic_W3, Independent_W3, Determined_W3, Professional_W3, Studious_W3, Imaginative_W3, Analytic_W4, Independent_W4, Determined_W4, Professional_W4, Studious_W4, Imaginative_W4, Analytic_W5, Independent_W5, Determined_W5, Professional_W5, Studious_W5, Imaginative_W5, Analytic_W6, Independent_W6, Determined_W6, Professional_W6, Studious_W6, Imaginative_W6, Analytic_W7, Independent_W7, Determined_W7, Professional_W7, Studious_W7, Imaginative_W7, Analytic_W8, Independent_W8, Determined_W8, Professional_W8, Studious_W8, Imaginative_W8, Analytic_W9, Independent_W9, Determined_W9, Professional_W9, Studious_W9, Imaginative_W9, Analytic_W10, Independent_W10, Determined_W10, Professional_W10, Studious_W10, Imaginative_W10, date, tech_self_score, strengths, weaknesses, self_development, geo_flex, financial_support_self, result, course_interest, id, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by, Thursday 1 August 2019, None, Wednesday 1 May 2019, Tuesday 1 October 2019, Wednesday 10 April 2019, Tuesday 10 December 2019, Thursday 10 January 2019, Wednesday 10 July 2019, Thursday 10 October 2019, Tuesday 10 September 2019, Thursday 11 April 2019, Wednesday 11 December 2019, Thursday 11 July 2019, Tuesday 11 June 2019, Wednesday 11 September 2019, Thursday 12 December 2019, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 237 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test search for a user\n",
    "gregor_gomez_records = merged_data[merged_data['name'] == 'Gregor Gomez']\n",
    "gregor_gomez_records_all_columns = merged_data.loc[merged_data['name'] == 'Gregor Gomez']\n",
    "# Filtered records for Gregor Gomez\n",
    "print(\"Filtered records for Gregor Gomez:\")\n",
    "print(gregor_gomez_records)\n",
    "\n",
    "# All columns for Gregor Gomez\n",
    "print(\"\\nAll columns for Gregor Gomez:\")\n",
    "print(gregor_gomez_records_all_columns)\n",
    "\n",
    "# Will return empty df as this is a trainer who will not be in some of the other tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a1b206c-d399-4c7b-a7c8-f544dc667650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NaN values in the entire dataframe with 0\n",
    "#merged_data_filled = merged_data.fillna(0)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "#print(\"Merged Data with NaN values filled with 0:\")\n",
    "#print(merged_data_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ddeb0e9c-ec7a-4832-a813-1910b30aa4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NaN values in the entire dataframe with 0\n",
    "#merged_data_filled = merged_data.fillna(0)\n",
    "\n",
    "# Test search for a user\n",
    "#gregor_gomez_records = merged_data_filled[merged_data_filled['name'] == 'Gregor Gomez']\n",
    "#gregor_gomez_records_all_columns = merged_data_filled.loc[merged_data_filled['name'] == 'Gregor Gomez']\n",
    "\n",
    "# Filtered records for Gregor Gomez\n",
    "#print(\"Filtered records for Gregor Gomez:\")\n",
    "#print(gregor_gomez_records)\n",
    "\n",
    "# All columns for Gregor Gomez\n",
    "#print(\"\\nAll columns for Gregor Gomez:\")\n",
    "#print(gregor_gomez_records_all_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "61e99e16-d0fe-4719-bc26-bd54256ad799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Unique names in the dataset:\")\n",
    "#print(merged_data_filled['name'].unique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
