# Data402_Final_Project
The repository for the work produced on the project by Data group 402.

## Data cleaning: JSON files
Within the 'Talent' prefix in the final project bucket, we have over 3000 JSON files that include information on potential talent for Sparta Global. To clean this, we first ensured that the files could all be brought together. This involved the accruement of the individual files into a single (relatively) large JSON file via python, labelled 'talent.json'. From this, within python still the files were inputted into a data frame via the python package "pandas". Through pandas, a data frame containing all of these JSON files was analysed for possible cleaning. It was noted that 55 of the in-total 3105 files did not contain information for the column 'tech_self_score'. While these in their individual files would have been simply missing, when placed in the data frame these 55 rows contained `NaN` under this column. We could have just dropped these 55 rows, it would be very miniscule compared to the total 3105 rows, but this was decided against as it wasn't impossible to deduce what would be in the `NaN` data. Simply, we converted all of the `NaN` values within 'tech_self_score' to be a string resembling an empty dictionary, '{}'. 

This string may seem odd as a choice, but it actually proved to be valuable as next we had to find duplicates. The data itself was not cooperative within pandas to find these duplicate values, as pandas cannot deduce what is within lists and dictionaries (lists being mentioned due to their presence in other columns) when searching for duplicate rows. To alleviate this, the three rows that were either comprised of dictionaries or lists were converted so that they were all now classed as strings. Once everything has become a string, the duplicated rows can be found. In searching for duplicates, we found 32 rows indicated as such. Once we knew the amount of duplicates was small, the command `drop_duplicates()` was used on the data frame, allowing us to have a finalised data frame with still over 3000 rows, containing no `NaN` values.
